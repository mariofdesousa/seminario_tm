---
title: "Seminário - Mineração de Texto"
author: "Fabiana, Fernando, Mário, Rafael e Rodney"
date: "Junho de 2017"
output:
  html_document:
    css: button.css
    highlight: haddock
    number_sections: yes
    theme: journal
    toc: yes
    toc_depth: 2
    toc_float:
      collapsed: no
      smooth_scroll: no
bibliography: bibliografia.bib
---
<script src="hideOutput.js"></script>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Metodologia


Sabemos que com a popularização da internet, um enorme volume dados é gerado a cada minuto. Durante anos, aprendemos a tabular e quantificar variáveis acomodadas em bancos de dados, porém os tempos são outros.

Estamos trabalhando com o estudo computacional de opiniões, sentimentos e emoções expressos em texto, e para tal, será preciso criar métricas para contabilização dos mesmos.

No trabalho a seguir, utilizamos o R para tratar estes textos e resolver o nosso problema através de diferentes técnicas de mineração de textos, com análise de sentimentos, nuvem de palavras e análise de tópicos, por exemplo. Adicionalmente, propomos uma nova métrica para mensurar o nível de depressão de uma pessoa através dos seus textos no Twitter.

## Descrição dos dados
A base de dados utilizada contém 30000 tweets extraídos com auxílio da função $\texttt{searchTwitter}$ do pacote $\texttt{twitteR}$. O banco de dados é composto por 10000 tweets escritos em inglês durante o período que compreende 01/01/2015 a 06/06/2017, contendo as palavras "depression", "depressive" e "depressed". 

A função $\texttt{searchTwitter}$ retorna uma lista com diversas informações, então faz-se necessário aplicar a função $\texttt{twListToPdf}$, também disponível no pacote $\texttt{twitteR}$, para transformar a lista do twitter em um dataframe compatível com as técnicas de manipulação de textos  $\texttt{tidy}$ e $\texttt{tm}$.

Quando se deseja aplicar técnicas de mineração de texto, a "limpeza" do conjunto textual selecionado é de fundamental importância. Este procedimento tem como objetivo retirar palavras que não acrescentam significado próprio ao texto. Este conjunto de palavras geralmente recebe o nome de *stopwords*. As *stopwords*  são problemáticas pois ao mesmo tempo que não acrescentam valor semântico, são muito frequentes\footnote{por serem compostos por artigos, preposições e pronomes.}. No caso em questão, utilizou-se , primeiramente, o método clássico, onde se utilzia uma lista pré-concebida de palavras para cada idioma @v15, contudo é relevante mencionar que em etapas posteriores novas palavras foram incluídas na lista de *stopwords*.

## Contagem e frequência de palavras

Segundo @gomes2013text, o desafio é saber como manipular essa grande quantidade de informação gerada e investigar como as organizações podem se beneficiar dessas informações, considerando que 80% das informações das organizações estão contidas em documentos de texto [@Tan99textmining].

O primeiro passo será realizar a contagem e frequência das palavras chave escolhidas pelo grupo.

Uma vez contabilizada a quantidade de palavras que aparecem dentro de um banco de dados pré estabelecido, é possível calcular a frequência percentual, das palavras e utilizar o pacote $\texttt{ggplot2}$ para elaboração de um histograma para visualização. 

### Nuvem de palavras

Outra opção de identificação de concentração de palavras na análise de sentimentos, são as nuvens de palavras que são imagens que demonstram de maneira visual a frequência da ocorrência das palavras em um dado texto.

Após criarmos um arquivo com a contagem das palavras, quanto maior for o número de ocorrências de uma palavra, maior a mesma será na nuvem de palavras.  As wordclouds são feitas com as palavras mais utilizadas em um determinado texto ou documento, de forma que o aspecto visual fique concentrado nas palavras mais importantes.

Para a nossa base de dados foram utilizados tweets da plataforma social "twitter", sendo que foram baixados 30.000(trinta mil) tweets, tendo a partir deles palavras relacionadas a depressão, sendo todas no idioma inglês, como "depression" e "anxiety".

Dado isso foi feita uma separação dos dados na linguagem R e os dados foram transformados em "Data Frame" para manipulação. Depois fizemos todas as limpezas necessárias para que o texto ficasse uniforme, como deixar todas as letras minúsculas, remover os nomes de usuário, tirar pontuação, links e espaços em branco desnecessários e, por fim, números e palavras desnecessárias, como a identificação do aparelho pelo qual foi enviado o tweet.

## Análise de tópicos

Um interesse usual em análises de grandes volumes de textos é classicar os documentos em diferentes tópicos, permitindo idetificar ou validar grupos entre os documentos analisados.  

Uma forma de realizar esse tipo de análise é utilizar o método de alocação latente de Dirichlet (LDA, na sigla em inglês), que foi proposto por @blei2003latent. Esse método é bastante conhecido na literatura de mineração de texto pela sua eficiência, já tendo sido aplicado em análises de e-mails, livros digitais e notícias, por exemplo, como destacam @berry2010text.

As principais características do LDA, como apresentam @Silge2017Text, são as seguintes:

* Documentos diferentes são formados por misturas de tópicos: Dados dois documentos $A$ e $B$, e tópicos distintos 1 e 2, podemos ter que o $A$ é formado em 75% por conteúdo sobre o tópico 1 e em 25% sobre o tópico 2, enquanto $B$ é formado em 40% sobre o tópico 1 e 60% sobre o tópico 2, por exemplo.

* Diferentes palavras podem fazer parte de diferentes tópicos: a palavra "estudante" pode estar mais associada a um tópico sobre universidades enquanto que "cliente" pode ser mais associado a um tópico sobre empresas, mas o termo "dados" pode estar relacionado de maneira similar a ambos esses tópicos.

Para exemplificar as suposições do modelo LDA vamos considerar as seguintes notações: uma palavra $w$ é uma unidade discreta de um conjunto que forma o vocabulário utilizado; um documento $\mathbf{w} = \left(w_1,\ldots,w_N\right)$ é um conjunto de $N$ palavras; um corpo $D=\left\{\mathbf{w}_1,\ldots,\mathbf{w}_M\right\}$ é um conjunto de $M$ documentos. Adicionalmente, no LDA o número de tópicos existentes é assumido conhecido, mas os tópicos em si são variáveis latentes que não conhecemos e desejamos estimar. Dessa maneira, @blei2003latent consideram as seguintes suposições na geração do corpo:

1. Gera-se $N\sim \textrm{Pois}\left(\lambda\right)$;
2. Gera-se $\theta = \textrm{Dirichlet}\left(\mathbf{\alpha}\right)$, o qual será o vetor de probabilidades dos $k$ tópicos;
3. Para cada uma das $N$ palavras $w_n$:

+ Sorteia-se um tópico $z_n \sim \textrm{Multinomial}\left(k,\theta\right)$

+ Sorteia-se uma palavra $w_n$ de $p\left(w_n|z_n,\beta\right)$, que segue uma distribuição multinomial cujas probabilidades são condicionadas no tópico $z_n$ e em um vetor desconhecido de parâmetros $\beta$.


A aplicação do LDA apresentada por @blei2003latent é baseada em um modelo Bayesiano com três níveis hierárquicos, e permite estimar a probabilidade que cada palavra tem de pertencer à cada um dos tópicos, bem como estimar a probabilidade de cada documento ser sobre cada tópico.

No programa $\texttt{R}$ a análise de tópicos pode ser realizada através do pacote $\texttt{topicmodels}$, utilizando a função $\texttt{LDA}$. Uma aplicação dessa função do $\texttt{R}$ é fornecida por @Silge2017Text em um exemplo onde livros distintos são tratados como tópicos e seus respectivos capítulos como documentos; no exemplo dos autores, mostra-se que o LDA consegue classificar quase todos capítulos corretamente em seus respectivos livros, demonstrando a eficiência do método.

## Análise de sentimentos

Em análise de sentimentos o principal objetivo consiste em fazer "inferência" sobre sentimetos expressos em forma de texto. @messias2017 citam algumas das recentes aplicações da referida metodologia, sendo as principais:

* Monitorar a reputação de alguma empresa ou marca;
* Fornecer perspectivas analíticas para investidores sobre determinado mercado (se certo mercado tem potencial ou não);
* Rastrear opiniões associadas a certos políticos (tais informações são úteis para o marketing do candidato) e
* Proporcionar meios de mensurar o bem-estar dos usuários de certo modelo de smartphone.

@goncalves2013 discutem que não há a "melhor" técnica para se aplicar em análise de sentimentos. Conclusão semelhante foi obtida por @ribeiro2016 após comparar 22 métodos diferentes em 18 documentos onde não foi possível encontrar um método que fosse igualmente bom, em termos de classificação, para todos os textos. 

Na aplicação sobre depressão iremos considerar os dicionários de sentimentos **afinn** [@afinn2011], **bing** [@bing2005] e **nrc** [@nrc2013], por estarem disponíveis no R. 

Os três dicionários são compostos por unigramas, i.e., palavras únicas. Os vocabulários contém palavras em que são associados scores relativos a sentimentos positivos ou negativos. No caso do **nrc** há associação de palavras a sentimentos como alegria, raiva, tristeza, negatividade, surpresa, medo e desgosto. Esta classificação é feita de modo binário (sim ou não), se determinada palavra corresponde a determinado sentimento. Já no vocabulário **bing** as palavras são classificadas, também de modo binário, porém não há distinção de sentimentos. As palavras ou são associadas a sentimentos positivos ou a negativos. Por fim, o vocabulário **afinn** atribui scores que vão de -5 a 5 para as palavras, de modo que quanto mais próximo de -5 mais negativa é aquela palavra e, de modo análogo, quanto mais próximo de 5 mais posiva é a palavra. Os três vocabulários estão disponívels no $\texttt{R}$ no pacote $\texttt{tidytext}$. 

Geralmente os dicionários são elaborados pelos próprios autores com auxílio de crowdsourcing. Geralmente há algum tipo de validação cruzada para testar o dicionário criado. Neste contexto fica evidente que os vocabulários são contemporâneos, ou seja, não é recomendado aplicar um dicionário de sentimentos atual para analisar um texto muito antigo, de séculos atrás por exemplo. Tal análise pode ser feita, mas devem ser tomados os devidos cuidados ao analisar os achados.

Iniciamos a análise de sentimentos com o vocabulário **nrc** para obtermos palavras relacionadas a cada um dos sentimentos, sendo eles alegria, raiva, tristeza, negatividade, surpresa, medo e desgosto, de modo que obtemos gráficos de contagem de palavras para cada um deles. Essa técnica permite avaliar quais palavras estão associadas a quais sentimentos no contexto de depressão. Prosseguimos a análise de sentimentos com o dicionário **bing**, sendo possível construir índices baseados nos tipos de palavras (positiva ou negativa) e na quantidade de ocorrência das mesmas em um grupo de $n$ linhas. 

Esse tipo de técnica permite avaliar alterações, caso existam, de sentimentos ao longo do texto. Note que a quantidade de linhas que serão agrupadas depende do tipo e do tamanho do texto que está sendo análisado. Ainda utilizando o dicionário **bing**, apresentamos uma núvem de palavras de sentimentos, isto é, uma nuvem de palavras com distinção entre palavras positivas e negativas. Prosseguimos a análise de sentimentos comparando os três dicionários, de modo a observar se há alguma discrepância em algum deles. 

Prosseguimos com a análise de sentimentos com bigramas, isto é, consideramos grupos de duas palavras ao invés de uma. Os bigramas são interessantes pois certa palavra precedida de outra pode alterar completamente o sentido da expressão. O exemplo mais claro é de uma palavra a princípio indica alguma afirmação sobre alguma coisa quando analisada enquanto unigrama, mas ao observar os bigramas tal palavra é precedida por "not", alterando o entendimento que havia sido feito pelo unigrama. No contexto de depressão os bigramas são de grande utilidade pois nos permitem observar quais palavras geralmente precedem as palavras "depression", "depressive" ou "depressed" e, deste modo, podemos avaliar com mais clareza os sentimentos associados a essas palavras. Neste mesmo sentido realizamos um estudo de correlação entre palavras de modo  a avaliar a correção entre palavras em termos de proximidade no texto. Ferramenta útil para melhorar o entendimento dos sentimentos expressos nos tweets.

## Dendrogramas

De acordo com o dicionário Merriam-Webster[^1], um dendograma se define como um diagrama em árvore que representa uma hierarquia de grupos de objetos, baseada em sua similiaridade ou características em comum. No caso dos dendogramas textuais, as palavras são os elementos que compõem os grupos do diagrama. A distância medida entre elas, por sua vez, depende da frequência de ocorrência de cada palavra. Definidos os grupos e sua respectiva hierarquia, o objetivo do dendrograma é facilitar a associação entre as palavras a fim de se extrair informações relevantes sobre o texto [@t17].

Diversos métodos podem ser utilizados para o agrupamento de objetos. O dendrograma é o resultado em diagrama de um método aglomerativo hierárquico. Neste método, cada objeto da análise é inicialmente considerado como um grupo individual. Em seguida, objetos com pouco distância entre si são aglomerados em grupos maiores. Estes  grupos maiores, por seu turno, são reagrupados, novamente segundo a distância entre seus objetos. Ao final do processo, todos os grupos se aglomeram em apenas um. A vizualização deste processo é o próprio dendrograma \cite{http://www.stewartschultz.com/statistics/books/Cambridge%20Dictionary%20Statistics%204th.pdf}.

No R, existem seis métodos de mensuração da distância entre os objetos, no caso, a frequência das palavras e oito métodos de aglomeração. Dentre as distâncias, podemos listar:

1) **Euclidiana**: o método padrão de distância entre vetores; 
$$\sum{(x_i- y_i)^2}$$

2) **Máximos**: mede a distância máxima entre componentes de dois vetores;
$$\max{|x_i - y_i|}$$

3) **Manhattan**: mede a distância absoluta entre dois vetores; 
$$\sum{|x_i- y_i|}$$

4) **Canberra**: definido pela seguinte expressão, onde termos nulos do denominador são excluídos da amostra;
$$\sum\frac{|x_i - y_i|}{ |x_i + y_i|}.$$ 

5) **Binário**: A distância é a proporção de vetores considerados binários, (*bits*), em que apenas um dos vetores está presente dentre aqueles em que apenas os vetores 1 estão incluídos e 

6) **Minkowski**: a p-ésima raíz da soma dos das diferenças dos componentes elevada à p-ésima potência. 
$$\sqrt[p]{\sum(x_i-y_i)^p}$$

Com relação à aglomeração, em cada estágio do processo a distância entre os grupos é recalculada pelo algorítimo de Lance-Willians \cite(https://pdfs.semanticscholar.org/7c16/8b8262acf2ec40a971604f273462136f4835.pdf), em acordo com o método de agrupamento selecionado. Os métodos implementados no R, segundo o pacote $\texttt{dentextend}$, são:"Ward","Single","Median","Centroid" e "Complete". 

O processo de construção do dendograma consiste, após a eliminação destas palavras, de contruir  uma matriz de frequência das palavras e selecionar as $n$  palavras mais frequentes, número estimado como parâmetro máximo para a representação de um dendrograma. As etapas seguintes são: a escolha da distância, do método de aglomeração e, por fim, do modo de apresentação do dendograma. No caso em questão utilizou-se a distância euclidiana, o método de aglomeração conhecido como "complete" e, como forma de apresentação, o dendograma circular por ser visualmente mais atrativo e informativo. 

# Resultados e discussões

## Contagem de palavras

<div class="fold s o">
```{r, message=FALSE,results='hide',echo=TRUE}

if("dplyr" %in% rownames(installed.packages())==FALSE)
{install.packages("dplyr");library(dplyr)};library(dplyr)

if("stringr" %in% rownames(installed.packages())==FALSE)
{install.packages("stringr");library(stringr)};library(stringr)

if("tidytext" %in% rownames(installed.packages())==FALSE)
{install.packages("tidytext");library(tidytext)};library(tidytext)

if("tidyr" %in% rownames(installed.packages())==FALSE)
{install.packages("tidyr");library(tidyr)};library(tidyr)

if("ggplot2" %in% rownames(installed.packages())==FALSE)
{install.packages("ggplot2");library(ggplot2)};library(ggplot2)

if("twitteR" %in% rownames(installed.packages())==FALSE)
{install.packages("twitteR");library(twitteR)};library(twitteR)

if("tibble" %in% rownames(installed.packages())==FALSE)
{install.packages("tibble");library(tibble)};library(tibble)

if("wordcloud" %in% rownames(installed.packages())==FALSE)
{install.packages("wordcloud");library(wordcloud)};library(wordcloud)

if("tm" %in% rownames(installed.packages())==FALSE)
{install.packages("tm");library(tm)};library(tm)

udemytweets <-readRDS("depression_tweets_final.gzip")
tweets.df <- twListToDF(udemytweets) ##CALMA QUE VAI DEMORAR
tweets_tidy_df <- as_tibble(tweets.df)

# Limpando a base de dados

replace_reg <- "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https"
unnest_reg  <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"

### Palavras retiradas para contagem
mystopwords_count <- c(stop_words$word,"depression","depressive","depressed",
                  "im","wcw","ur","depressed.","depression.","depressed,",
                  "depression,","me,","lol","#depression","me.","wow",
                  "depressed?","idk","ppl","bc","dont","lot","it.","anxiety,",
                  "her,","af","y'all","rn")

### Limpando a base para a contagem de palavras
tweets_tidy_count <- tweets_tidy_df %>% 
  filter(!str_detect(text, "^RT"),
         text != "im",
         text != "ur",
         text != "af",
         text != "wcw",
         text != "shes",
         text != "booktweeter0",
         text != "bktwr",
         !str_detect(text, "[0-9]"),
         !str_detect(text, ":"),
         !str_detect(text, "textless")) %>%
  mutate(text = str_replace_all(text, replace_reg, "")) %>%
  unnest_tokens(word, text, token = "regex") %>%
  filter(!word %in% mystopwords_count,
         str_detect(word, "[a-z]")) %>%
  anti_join(stop_words)%>%
  count(word,sort=TRUE)%>%
  filter(n > 100 & n < 500) %>%
  mutate(word = reorder(word, n)) 
```
</div>

As nuvens de palavras são comuns em contagem de palavras por serem visualmente atrativas e de fácil interpretação. As palavras com maior número de repetição nos documentos são adicionadas de  maneira que miniminiza os espaços em branco de acordo com os tamanhos das palavras, que é proporcional à quantidade de vezes que elas aparecem. 

<div class="fold s">
```{r, message=FALSE,results='hide',echo=TRUE}
tweets_tidy_df %>% 
  filter(!str_detect(text, "^RT"),
         text != "im",
         text != "ur",
         text != "af",
         text != "wcw",
         text != "shes",
         text != "booktweeter0",
         text != "bktwr",
         !str_detect(text, "[0-9]"),
         !str_detect(text, ":"),
         !str_detect(text, "textless")) %>%
  mutate(text = str_replace_all(text, replace_reg, "")) %>%
  unnest_tokens(word, text, token = "regex") %>%
  filter(!word %in% mystopwords_count,
         str_detect(word, "[a-z]")) %>%
  anti_join(stop_words)%>%
  count(word,sort=TRUE)%>%
  mutate(word = reorder(word, n)) %>%
  with(wordcloud(word, n, max.words = 100,colors=brewer.pal(8, "Paired"),  
          random.color= TRUE))
```
</div>

 No caso em questão observa-se elevada quantidade de palavras de cunho negativo como "anxiety", "sad", "stressed", "shit", "feel", "hate", "lost", "tired" ,"episode" e "fucking". As palavras "feel" e "episode" não necessariamente estão relacionadas a depressão, contudo a análise de bigramas apresentada adiante apresenta evidências de que tais palavras geralmente precedem as palavras "depressed" ou "depressive", formando expressões como "depressive episode", "fucking depressed" e "feeling depressive." 

Em seguida é apresentado um histograma da frequência de palavras. Geralmente as expressões mais comuns possuem frequência maior, enquanto expressões mais específicas possuem baixa frequencia. O histograma de proporções geralmente evidencia o padrão de escrita do autor, onde maior assimetria à direita evidencia a característica do(s) autor(es) de repetir pouco as palavras. 

<div class="fold s">
```{r, message=FALSE,results='hide',echo=TRUE,warning=FALSE}
### Histograma da proporcao de palavras
### Palavras retiradas do histograma

mystopwords_hist <- c(stop_words$word,"im","wcw","ur",
                         "depressed.","depression.","depressed,")
tweets_tidy_df %>% 
    filter(!str_detect(text, "^RT"),
           text != "im",
           text != "ur",
           text != "af",
           text != "wcw",
           text != "shes",
           text != "booktweeter0",
           text != "bktwr",
           !str_detect(text, "[0-9]"),
           !str_detect(text, ":"),
           !str_detect(text, "textless")) %>%
    mutate(text = str_replace_all(text, replace_reg, "")) %>%
    unnest_tokens(word, text, token = "regex") %>%
    filter(!word %in% mystopwords_hist,
           str_detect(word, "[a-z]")) %>%
    anti_join(stop_words)%>%
    count(word,sort=TRUE)%>%
    mutate(word = reorder(word, n)) %>%
ggplot(aes(n/sum(n))) +
  geom_histogram(show.legend = FALSE) +
  xlim(NA, 0.0009) +
  xlab("Proporção")+
  ylab("Contagem")
```
</div>

O histograma para o conjunto de dados analisados está de acordo com a literatura, isto é, mostra evidências de que os usuários tendem a usar muitas palavras comuns, o que explica a barra próxima do 0. Ainda em consonância com a literatura é possível observar que a contagem de palavras com proporções maiores decresce rapidamente, evidenciando que no conjunto de dados analisados os usuários possuem a característica de repetir pouco as palavras.  

## Análise de sentimentos

<div class="fold s">
```{r, message=FALSE,results='hide',echo=TRUE}

mystopwords <- c(stop_words$word)

tidy_tweets <- tweets_tidy_df %>% 
  filter(!str_detect(text, "^RT"),
         text != "im",
         text != "ur",
         text != "af",
         text != "wcw",
         text != "shes",
         text != "booktweeter0",
         text != "bktwr",
         !str_detect(text, "[0-9]"),
         !str_detect(text, ":"),
         !str_detect(text, "textless")) %>%
  mutate(text = str_replace_all(text, replace_reg, "")) %>%
  unnest_tokens(word, text, token = "regex") %>%
  filter(!word %in% mystopwords,
         str_detect(word, "[a-z]")) %>%
  anti_join(stop_words)

nrneg <- get_sentiments("nrc") %>% 
  filter(sentiment == "negative")

tidy_tweets %>%
  inner_join(nrneg) %>%
  count(word, sort = TRUE)%>%
  filter(n > 25 & n < 500) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab("Negative") +
  ylab("Número de ocorrências")+
  coord_flip()
```
```{r message=FALSE,results='hide',echo=TRUE}
#####sadness    
nrsad <- get_sentiments("nrc") %>% 
  filter(sentiment == "sadness")

tidy_tweets %>%
  inner_join(nrsad) %>%
  count(word, sort = TRUE) %>%
  filter(n > 25 & n < 500) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab("Sadness") +
  ylab("Número de ocorrências")+
  coord_flip()
```
```{r message=FALSE,results='hide',echo=TRUE}
#####         anger                      ####   
nrang <- get_sentiments("nrc") %>% 
  filter(sentiment == "anger")

tidy_tweets %>%
  inner_join(nrang) %>%
  count(word, sort = TRUE) %>%
  filter(n > 15 & n < 500) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab("Anger") +
  ylab("Número de ocorrências")+
  coord_flip() 
```
```{r message=FALSE,results='hide',echo=TRUE}
#####  fear      
nrfear <- get_sentiments("nrc") %>% 
  filter(sentiment == "fear")

tidy_tweets %>%
  inner_join(nrfear) %>%
  count(word, sort = TRUE) %>%
  filter(n > 25 & n < 500) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab("Fear") +
  ylab("Número de ocorrências")+
  coord_flip() 
```
```{r message=FALSE,results='hide',echo=TRUE}
##### disgust 
nrdisg <- get_sentiments("nrc") %>% 
  filter(sentiment == "disgust")

tidy_tweets %>%
  inner_join(nrdisg) %>%
  count(word, sort = TRUE) %>%
  filter(n > 15 & n < 500) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab("Disgust") +
  ylab("Número de ocorrências")+
  coord_flip() 
```
</div>

Utilizando o dicionário **nrc**, observamos a frequência de palavras relacionadas aos sentimentos contidos no dicionário. O objetivo deste tipo de análise é verificar quais palavras estão associadas a quais sentimentos no âmbito da análise em questão.

É interessante destacar que palavras relacionadas a ansiedade, suicídio, morte e cansaço são recorrentes com alta frequência quando contrastamos os sentimentos "negative", "anger", "fear" e "disgust". Este resultado é interessante pois a literatura comumente não encontra alta frequência de palavras associadas a sentimentos distintos. A palavra "anxiety" merece atenção especial uma vez que há referências robustas relacionando ansiedade com depressão e, possivelmente, suicídio. 

<div class="fold s">
```{r message=FALSE,results='hide',echo=TRUE}
#####surprise  
nrsurp <- get_sentiments("nrc") %>% 
  filter(sentiment == "surprise")

tidy_tweets %>%
  inner_join(nrsurp) %>%
  count(word, sort = TRUE) %>%
  filter(n > 15 & n < 500) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab("Surprise") +
  ylab("Número de ocorrências")+
  coord_flip() 
```
</div>

Ao comparar a frequência de palavras relacionadas ao sentimento "surprise" observa-se a presença de diversas palavras positivas. Um resultado curioso é a presença da palavra "Trump", uma óbvia referência ao presidente dos Estados Unidos Donald Trump. Ainda avaliado as ocorrências em "surprise" nota-se que "hope" é uma palavra que aparece com relativa frequência nos tweets relacionados com depressão. Obviamente, "money", também aparece com certa frequência

<div class="fold s">
```{r message=FALSE,results='hide',echo=TRUE}
################# Dicionário Bing      
 tweets_tidy_df %>% 
  filter(!str_detect(text, "^RT"),
         text != "im",
         text != "ur",
         text != "af",
         text != "wcw",
         text != "shes",
         text != "booktweeter0",
         text != "bktwr",
         !str_detect(text, "[0-9]"),
         !str_detect(text, ":"),
         !str_detect(text, "textless")) %>%
  mutate(text = str_replace_all(text, replace_reg, ""),
         line = row_number()) %>%
  unnest_tokens(word, text, token = "regex") %>%
  anti_join(stop_words) %>%
  filter(!word %in% mystopwords,
         str_detect(word, "[a-z]"))%>%
  inner_join(get_sentiments("bing"))%>%
  count(index = line %/% 150, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative) %>%
  ggplot(aes(index, sentiment)) +
  geom_col(show.legend = FALSE) +
  xlab("Index")+
  ylab("Score")
```
</div>

O gráfico acima, criado a partir do dicionário **bing** é conciso em informar que a base de dados em questão possui elevada aparição de palavras negativas. Note que no dicionário **nrc** encontramos certas palavras positivas associadas ao sentimento "surprise", contudo essas palavras não alteram a característica extremamente negativa do texto. Esta conclusão é obtida ao observarmos que em grupos de 150 não há nenhum com score positivo. 

<div class="fold s">
```{r message=FALSE,results='hide',echo=TRUE}
################# Dicionário afinn              #################     

afinn <-  tweets_tidy_df %>% 
          filter(!str_detect(text, "^RT")) %>%
          mutate(text = str_replace_all(text, replace_reg, ""),
          line = row_number()) %>%
          unnest_tokens(word, text, token = "regex") %>%
          anti_join(stop_words) %>%
          filter(!word %in% mystopwords,
          str_detect(word, "[a-z]"))%>%
          inner_join(get_sentiments("afinn")) %>% 
          group_by(index = line %/% 20) %>% 
          summarise(sentiment = sum(score)) %>% 
          mutate(method = "AFINN")
################# Comparação de Dicionário     #################     
bing_and_nrc <- bind_rows(tweets_tidy_df %>%
                            filter(!str_detect(text, "^RT")) %>%
                            mutate(text = str_replace_all(text, replace_reg, ""),
                            line = row_number()) %>%
                            unnest_tokens(word, text, token = "regex") %>%
                            anti_join(stop_words) %>%
                            filter(!word %in% mystopwords,
                                     str_detect(word, "[a-z]"))%>% 
                            inner_join(get_sentiments("bing")) %>%
                            mutate(method = "Bing et al."),
                            tweets_tidy_df %>%
                            filter(!str_detect(text, "^RT")) %>%
                            mutate(text = str_replace_all(text, replace_reg, ""),
                                     line = row_number()) %>%
                            unnest_tokens(word, text, token = "regex") %>%
                            anti_join(stop_words) %>%
                            filter(!word %in% mystopwords,
                                     str_detect(word, "[a-z]"))%>% 
                            inner_join(get_sentiments("nrc") %>% 
                            filter(sentiment %in% c("positive","negative"))) %>%
                            mutate(method = "NRC")) %>%
                            count(method, index = line %/% 20, sentiment) %>%
                            spread(sentiment, n, fill = 0) %>%
                            mutate(sentiment = positive - negative)

bind_rows(afinn,bing_and_nrc) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  ylab("Score")+
  xlab("Index")+
  facet_wrap(~method, ncol = 1, scales = "free_y") 
```
</div>

A comparação entre os três dicionários corrobora o elevado caráter negativo das palavras utilizadas. É relevante ressaltar que, embora o dicionário **afinn** apresente os menores scores, é o dicionário que aponta mais scores positivos para grupos de 20 palavras. No caso aqui considerado os dicionários evidenciam resultados parecidos entre si. Para fins de comparação utilizou-se, para o vocabulário **nrc**, as palavras relacionadas aos sentimentos "positive" e "negative" do referido dicionário.

As análises realizadas até este ponto foram realizadas por meio de unigramas, isto é, análises de palavra por palavra em separado. Análises baseadas em unigramas podem não ser a melhor opção pois há composições de palavras que alteram completamente o sentido da frase. Um exemplo intuitivo e iminente são as palavras precedidas por "not". Quando este é o caso as análises de unigramas captam apenas o sentido de uma palavra, não há como saber se a referida palavra está precedida por "not", o que obviamente altera complemente o sentido da expressão. Para evitar tais problemas e obtermos as sequências de palavras mais frequentes no texto prosseguimos com uma análise baseada em bigramas, isto é, análises baseadas em composições de duas palavras ao invés de uma.

<div class="fold s">
```{r message=FALSE,results='hide',echo=TRUE}
#### Bigramas

tidy_tweets_big <- tweets_tidy_df %>% 
  filter(!str_detect(text, "^RT"),
         text != "im",
         text != "ur",
         text != "af",
         text != "wcw",
         text != "shes",
         text != "booktweeter0",
         text != "bktwr",
         !str_detect(text, "[0-9]"),
         !str_detect(text, ":"),
         !str_detect(text, "textless")) %>%
  mutate(text = str_replace_all(text, replace_reg, "")) %>%
  unnest_tokens(word, text, token = "ngrams",n=2) %>%
  filter(!word %in% mystopwords,
         str_detect(word, "[a-z]"))

tidy_tweets_big %>%
  count(word, sort = TRUE)

bigrams_separated <- tidy_tweets_big %>%
  separate(word, c("word1", "word2"), sep = " ")

bigrams_separated %>%
  filter(word1 == "depression") %>%
  count(word1, word2, sort = TRUE)

AFINN <- get_sentiments("afinn")

# We can then examine the most frequent words that were preceded by “word”  

depression_words <- bigrams_separated %>%
  filter(word1 == "depression") %>%
  inner_join(AFINN, by = c(word2 = "word")) %>%
  count(word2, score, sort = TRUE) %>%
  ungroup()

depression_words

depression_words %>%
  mutate(contribution = n * score) %>%
  arrange(desc(abs(contribution))) %>%
  head(20) %>%
  mutate(word2 = reorder(word2, contribution)) %>%
  ggplot(aes(word2, n * score, fill = n * score > 0)) +
  geom_col(show.legend = FALSE) +
  xlab("Palavras precedidas por \"depression\"") +
  ylab("Score * número de ocorrências") +
  coord_flip()
```
</div>

Em análise de bigramas algo relevante é a quantidade de vezes que alguma palavra de interesse, no caso "depression", é precedida de outras palavras. Observa-se a ocorrência de algumas palavras relacionadas positivas, sendo as principais "love" e "win". Pelo espectro negativo há de se ressaltar o elevado número de vezes em que a palavra "depression" é precedida de "anxiety", "kills" e palavras relacionadas a suicídio. Confirma-se, a priori, os achados nas análises de unigramas quando se comparou a ocorrência de palavras relacionadas a sentimentos do dicionário **nrc**. Naquele caso as palavras relacionadas a ansiedade e suicídio também apareceram com frequência elevada.

Ainda no contexto de bigramas há de se mencionar as redes de palavras. As redes de palavras são dispositivos visuais que auxiliam na compreensão da base de dados e dos sentimentos envolvidos.

<div class="fold s">
```{r message=FALSE,results='hide',echo=TRUE}

if("igraph" %in% rownames(installed.packages())==FALSE)
{install.packages("igraph");library(igraph)};library(igraph)
if("ggraph" %in% rownames(installed.packages())==FALSE)
{install.packages("ggraph");library(ggraph)};library(ggraph)
### Rede de palavras

mystopwords_rede <- c(stop_words$word,"rn","bc","wcw","af","lol")

bigrams_filtered <- bigrams_separated %>%
  filter(!word1 %in% mystopwords_rede) %>%
  filter(!word2 %in% mystopwords_rede)

bigram_counts <- bigrams_filtered %>% 
  count(word1, word2, sort = TRUE)

bigram_graph <- bigram_counts %>%
  filter(n > 10) %>%
  graph_from_data_frame()

bigram_graph

set.seed(2016)

a <- grid::arrow(type = "closed", length = unit(.15, "inches"))

## REDE DE PALAVRAS
ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n,edge_width = n), edge_colour = "darkred", show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "royalblue", size = 5) +
  geom_node_text(aes(label = name), repel=TRUE, point.padding = unit(0.2, "lines")) +
  theme_void()
```
</div>

A rede de palavras apresenta três nós nos entornos das palavras "depression", "depressive" e "depressed". Algo desta natureza já era esperado uma vez que foram realizadas buscas que continham estas palavras. É interessante observar que palavras de cunho técnico, "clinical", "severe", "deep" e "anxiety" estão relacionadas com a palavra "depression", ao passo que palavras de cunho pejorativo se encontram mais próximas de "depressed" e "depressive" se conecta, na grande parte dos casos, com palavras relacionadas ao grau de depressão ou a eventos relacionados à doença. 

É relevante destacar que outras conexões de palavras aparecem com relativa frequência ao longo do texto, sendo as principais: "hard"->"time", "mental"->"health", "social"->"media" e "love"->"island". Com excessão da última, as demais conexões estão relacionadas, segundo a literatura pertinente, com depressão sendo "social media" uma aparição bastante interessante.

No contexto da análise de sentimentos já está evidente que ansiedade possui relação próxima com depressão e sentimentos relacionados. Abaixo realizamos uma análise de correlação entre as palavras cujo objetivo é identifica palavras mais correlacionadas com algum termo específico, no caso "anxiety". 

<div class="fold s">
```{r message=FALSE,results='hide',echo=TRUE}
if("devtools" %in% rownames(installed.packages())==FALSE)
{install.packages("devtools");library(devtools)};library(devtools)
if("widyr" %in% rownames(installed.packages())==FALSE)
{install_github("dgrtwo/widyr");library(widyr)};library(widyr)

#Counting and correlating pairs of words with the widyr package
mystopwords_w_dep <- c(stop_words$word,"depression,")

word_cors <- tidy_tweets %>%
  group_by(word) %>%
  filter(!word %in% mystopwords_w_dep,
         str_detect(word, "[a-z]"),
         n() >= 15) %>%
  pairwise_cor(word, screenName, sort = TRUE)

#Palavras correlacionadas com depression
word_cors %>%
  filter(item1 %in% c("anxiety")) %>%
  group_by(item1) %>%
  top_n(8) %>%
  ungroup() %>%
  mutate(item2 = reorder(item2, correlation)) %>%
  ggplot(aes(item2, correlation)) +
  geom_bar(stat = "identity") +
  facet_wrap(~ item1, scales = "free") +
  ylab("Correlação")+
  xlab(NULL)+
  coord_flip()
```
</div>

As palavras mais correlacionadas com "anxiety" são "depression", "disorder" e "social". Mais uma vez se comprova a estreita relação entre ansiedade e depressão. A aparição da palavra "social" neste contexto é bastante interessante pois, segundo a rede de palavras, "social" é frequentemente seguido de "media", então conclui-se que há correlação positiva entre "social media" e "anxiety". Sendo assim observa-se que há estreita relação entre "social media" e depressão, relacão intermediada por "anxiety". 

## Análise de tópicos

Nesta etapa será realizada uma análise de tópicos para verificar se o método LDA é capaz de encontrar algum agrupar os tweets de alguma forma. Na análise, cada usuário do Twitter será visto como o "documento" do qual o texto faz parte. Para isso, criamos um banco de dados onde as palavras e suas frequências são agrupadas por usuários, identificados pelo $\texttt{screenName}$. Adicionalmente, será feita a suposição de que os textos fazem parte de dois grupos desconhecidos e através da função $\texttt{LDA}$ do pacote $\texttt{topicmodels}$, serão obtidas as probabilidades de cada palavra e de cada usuário (documento) pertencer a cada um dos grupos, que serão identificados pelos números 1 e 2.

<div class="fold s">
```{r message=FALSE,results='hide',echo=TRUE}
if("topicmodels" %in% rownames(installed.packages())==FALSE)
{install.packages("topicmodels");library(topicmodels)};library(topicmodels)

# Criando um tidy com contando as palavras por usuário
tidy_data <- tidy_tweets %>%
    group_by(screenName) %>%
    count(word, sort = TRUE) %>%
    filter(n >= 0)
# criando um DocumentTermMatrix para ser usado na função LDA
depre_dtm <- tidy_data %>% cast_dtm(screenName, word, n)

# aplicando a análise de tópicos
depre_lda <- LDA(depre_dtm, k = 2, control = list(seed = 1234))

# usando o tidy para extrair as probabilidades tópico/palavra
depre_topics <- tidy(depre_lda, matrix = "beta")

# aqui extraímos as palavras com maiores probabilidades de pertecerem
# a cada um dos tópicos
depre_top_terms <- depre_topics %>%
  group_by(topic) %>%
  top_n(5, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)
# gerando o gráfico
depre_top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  ylab(expression(beta))+
  xlab("Termo")+
  coord_flip()
```
</div>

Após o método LDA ser aplicado, o índice $\texttt{beta}$ fornece a probabilidade de cada palavra pertencer a um dos grupos. Durante a análise, notamos que não parece haver grupos distintos bem definidos nos tweets analisados, sendo os grupos 1 e 2 bastante similiras e com várias palavras em comum. Tal resultados também foi verificado quando se connsidera números maiores ($k$) de grupos desconhecidos. No gráfico acima são apresentadas para cada grupo identificado pelo LDA as palavras que possuem as maiores de $\texttt{beta}$. Apesar dos grupos 1 e 2 serem bastante parecidos, podemos observar que o primeiro grupo parece estar mais relacionado com o estado "depressed", enquanto no segundo grupo tem-se uma ênfase maior no sentimento "depression".

<div class="fold s">
```{r message=FALSE,echo=TRUE}
# Aqui calculamos a probabilidade de cada pessoa escrever sobre
# cada um dos tópicos
depre_topics_id <- tidy(depre_lda, matrix = "gamma")
depre_topics_id %>% group_by(topic) %>%
  top_n(3) %>% arrange(topic, desc(gamma))

# Aqui analisamos algumas das pessoas com as maiores probabilidades de 
# escrever sobre algum dos tópicos

# Exemplo 1
exemplo1 <- tweets.df %>% filter(screenName == "_Depressed_Zuka") %>%
  select(text)
exemplo1$text[15]

# Exemplo 2
exemplo2 <- tweets.df %>% filter(screenName == "Quixotitron_4") %>%
  select(text)
exemplo2$text[1]

# Exemplo 3
exemplo3 <- tweets.df %>% filter(screenName == "RF_NYC_2010") %>%
  select(text)
exemplo3$text[5]

# Exemplo 4
exemplo4 <- tweets.df %>% filter(screenName == "DepressionRoots") %>%
  select(text)
exemplo4$text[2]
```
</div>

Como mencionado, pelo LDA também podemos estimar uma probabilidade que cada usuário tem de pertencer a cada um dos grupos. De maneira similar como foi feito para as palavras, no código anterior identificamos dentro dos grupos 1 e 2 quais pessoas tinham as maiores probabilidades, que é dada pelo índice $\texttt{gamma}$. Acima são mostrados alguns textos dos usuários identificados pelo LDA, onde podemos ver que alguns dos textos parecem ser provenientes de pessoas com um nível expressivo de descontentamento ou tristeza, como os exemplos 1 e 3. No exemplo 2 temos um exemplo onde o usuário escreve diversos trechos relacionados ao livro Dom Quixote de Miguel de Cervantes, onde seus textos podem ter algum grau de tristeza mas não necessariamente indicar que a pessoa tenha depressão. No exemplo 4, o usuário escreve sobre depressão, o que pode explicar o fato dele ser incluído no grupo sobre o sentimento "depression". Em geral, notamos que o método LDA apresenta dificuldade em encontrar grupos dentro dos tweets analisados, mas que a medida de probabilidade para cada pessoa ainda pode fornecer um indicativo se cada pessoa está apresentando textos que se destacam dos demais, o que poderia ser um possível indício de sentimentos negativos que estajam relacionados ao estado de depressão.

## Dendogramas

<div class="fold s">
```{r message=FALSE,results='hide',echo=TRUE}
if("qdap" %in% rownames(installed.packages())==FALSE)
{install.packages("qdap");library(qdap)};library(qdap)
if("dendextend" %in% rownames(installed.packages())==FALSE)
{install.packages("dendextend");library(dendextend)};library(dendextend)

new_stops <-c(mystopwords,"lol","ur","bktwtr","booktweeter","im","https")
new_stops2 <-c(mystopwords,"depression", "lol","ur","bktwtr","booktweeter","amp","im","https","depressed","depression","depressive","depression")

# matriz de frequência de palavras
mat_freq  <- wfm(tidy_tweets$word)
mat_freq  <- as.matrix(mat_freq) #matriz de frequências
term_freq <-rowSums(mat_freq)
term_freq <-sort(term_freq,decreasing = T) # lista com as top palavras em orderm decrescente
```
</div>

Na análise de contagem de palavras as expressões **depressed**, **depression** e **depressive** são as mais frequentes, fato que era esperado devido ao fato de terem visto que foram utilizadas como filtro para a seleção dos tweets que compõem a base de dados do trabalho. A fim de se analisar de forma mais precisa a frequência deste subconjunto de dados, optou-se por retirar estas três observações a fim de tornar a escala de frequência da demais palavras mais clara, como pode-se observar abaixo. Para uma análise de dendrograma a contagem de palavras é de grande significância à medida em que os **clusters** são formados a partir das mesmas. O método selecionado de cálculo das distâncias entre as observações, no caso a distância entre as contagens, foi o euclidiano. Optou-se por utilizar o dendograma circular por ser mais atrativo em termos visuais e de transmissão de informação. 

<div class="fold s">
```{r message=FALSE,results='hide',echo=TRUE}
if("ape" %in% rownames(installed.packages())==FALSE)
{install.packages("ape");library(ape)};library(ape)

dend5 <- dist(term_freq[1:50]) %>% dist %>% hclust %>% as.dendrogram
plot(as.phylo(dend5), type="fan")
```
</div>

Além disso, pode-se notar que, como esperado, há um grande número de observações na mesma altura do dendrograma, que representam as aproximadamente trinta palavras com frequência semelhantes. Uma das vantagens da construção do dendrograma é o fato de que não é necesessário se definir, a priori, o número de grupos que o conjunto de palavras possui. A partir da análise desde dendrograma, optou-se por definir de forma a priori, o número de clusters, de forma a tornar possível sua vizualização de forma mais clara. O segundo dendrograma abaixo, ilustra o caso com oito grupos:Além disso, nota-se um grande número de palavras que expressam sentimentos, o que revela um padrão dos textos da base selecionada que se relaciona à saúde mental. Prosseguimos com a construção do dendrograma.



[^1]: ver https://www.merriam-webster.com/dictionary/dendrogram
[^2]: As palavras extras exluídas das análise foram: "https", "im" "ur", "lol", "bktwtr", "booktweeter".

## Índice de depressão e tristeza

Um dos objetivos desse trabalho é fornecer um método que seja capaz de identificar se uma pessoa apresenta sinais de depressão através dos seus textos no Twitter. Uma proposta que apresentamos nessa direção é utilizar um índice que leva em consideração a proporção de palavras relacionadas à depressão que cada usuário digitou. Para isso, consideramos uma lista de 99 palavras que possuem alguma relação com depressão fornecida na página da internet \cite(https://adarkershadeofblue.wordpress.com/2011/08/20/99-words-about-depression/). A palavra depressed também foi adicionada à essa lista, uma vez que na análise de redes essa palavras foi observada possuir uma maior relação com sentimentos depressivos que depressive e depression.

Considerando para cada usuário $n_{\text{tot}}$ o número total de palavras digitadas (desconsiderando stopwords) e $n_{\text{dep}}$ o número de palavras que estão presentes na lista de 100 palavras relacionadas à depressão, o índice que nós propomos é dado por
$$
\text{dep}_{\text{scr}} = 1 + \frac{1}{n_{\text{dep}}\times\log(1-p_{\text{dep}})-1},
$$
em que $p_{\text{dep}} = n_{\text{dep}}/n_{\text{tot}}$ é a proporção de palavras relacionadas com depressão do usuário. Pode-se notar que 
$$
p_{\text{dep}} \rightarrow 0 \Rightarrow \text{dep}_{\text{scr}} \rightarrow 0 \quad\text{e}\quad p_{\text{dep}} \rightarrow 1 \Rightarrow \text{dep}_{\text{scr}} \rightarrow 1,
$$ 
ou seja, quanto mais próximo de um for o valor de $\text{dep}_{\text{scr}}$, mais indícios a pessoa terá de estar escrevendo sobre algo relacionado à sentimentos de depressão. Vale destacar que se a análise fosse feita somente sobre $p_{\text{dep}}$, pessoas que escrevem pouco tenderiam a ter mais indícios de depressão mesmo contendo poucas palavras na lista utilizada. Ao se considerar $\text{dep}_{\text{scr}}$ ao invés de simplesmente $p_{\text{dep}}$, levamos em conta a ideia de que entre duas pessoas com o mesmo valor de $p_{\text{dep}}$, aquela com maior número de palavras depressivas $n_{\text{dep}}$ deverá ter um índice de depressão maior, enquante se duas pessoas tiverem o mesmo valor de $n_{\text{dep}}$, o valor de $\text{dep}_{\text{scr}}$ seja maior para o indivíduo com maior $p_{\text{dep}}$. 

Um problema com $\text{dep}_{\text{scr}}$ é que, se $p_{\text{dep}}$ tende à uma constante conforme $n_{\text{tot}}\rightarrow \infty$, então $n_{\text{dep}} \rightarrow \infty \Rightarrow \text{dep}_{\text{scr}} \rightarrow 1$, independente do valor limite de $p_{\text{dep}}$. Por outro lado, como mencionamos anteriormente, para valores finitos de $n_{\text{tot}}$ e $n_{\text{dep}}$ temos que $\text{dep}_{\text{scr}}$ fornece critérios de comparação mais adequados que utilizar somente $p_{\text{dep}}$. No código abaixo o valor de $\text{dep}_{\text{scr}}$ foi calculado para cada usuário analisado.

<div class="fold s">
```{r message=FALSE,echo=TRUE}
# Criando um tidy com contando as palavras por usuário
tidy_data <- tidy_tweets %>%
    group_by(screenName) %>%
    count(word, sort = TRUE) %>%
    filter(n >= 0)
# 99 palavras sobre depressão listadas no site abaixo mais depressed
# https://adarkershadeofblue.wordpress.com/2011/08/20/99-words-about-depression/
depre_words = c("depressed","abandoned","achy","afraid","agitated","agony","alone","anguish","antisocial","anxious","breakdown","brittle","broken","catatonic","consumed","crisis","crushed","crying","defeated","defensive","dejected","demoralized","desolate","despair","desperate","despondent","devastated","discontented","disheartened","dismal","distractable","distraught","distressed","doomed","dreadful","dreary","edgy","emotional","empty","excluded","exhausted","exposed","fatalistic","forlorn","fragile","freaking","gloomy","grouchy","hate","helpless","hopeless","hurt","inadequate","inconsolable","injured","insecure","irrational","irritable","isolated","lonely","lousy","low","melancholy","miserable","moody","morbid","needy","nervous","nightmarish","oppressed","overwhelmed","pain","paranoid","pessimistic","reckless","rejected","resigned","sadness","self-conscious","self-disgust","shattered","sobbing","sorrowful","suffering","suicidal","tearful","touchy","trapped","uneasy","unhappy","unhinged","unpredictable","upset","vulnerable","wailing","weak","weepy","withdrawn","woeful","wounded","wretched")

# Considere as seguintes variáveis
# ntot:total de palavras consideras
# ndep: total de palavras que estão na lista sobre depressão
# o índice utilizado foi 1 + 1/(ndep*log(1 - p) - 1), onde
# p=ndep/ntot. O índice assume valores entre 0 e 1, quando mais 
# próximo de 1 mais depressivo é o conteúdo do texto
tidy_dp_index <- tidy_data %>%  mutate(ntot = sum(n)) %>%
  filter(word %in% depre_words) %>%
  filter(ntot>9) %>%
  mutate(ndep = sum(n)) %>%
  mutate(dep_scr = (1 + 1/(ndep*log(1 - ndep/ntot) - 1))) %>%
  ungroup() %>%
  select(-c(word,n)) %>%
  unique() %>%
  arrange(desc(dep_scr))
ma1 <- tidy_dp_index %>% head(2)  # usuários com maiores índices
me2 <- tidy_dp_index %>% arrange(dep_scr) %>% head(2)  # usuários com menores índices

print(c(ma1,me2))
```
</div>

Abaixo apresentamos os dois usuários que apresentaram os maiores valores de $\text{dep}_{\text{scr}}$ e os dois usuários que apresentaram os menores $\text{dep}_{\text{scr}}$. Analisando trechos dos textos desses usuários, notamos que os dois primeiros apresentam teores bastante depressivos, com uma alta concentração de palavras negativas, diferentemente dos dois últimos textos, que parecem não serem tão expressivamente negativos como os anteriores. Em geral, notamos que $\text{dep}_{\text{scr}}$ permite identificar vários usuários que possuem textos com concentrações relativamente altas de palavras relacionadas à depressão, e consiste em uma nova proposta bastante simples para análise de textos relacionados à depressão, mas que também pode ser aplicado em diferentes tipos de análises de mineração de textos.

<div class="fold s">
```{r message=FALSE,echo=TRUE}
# textos de usuários detectados com maiores índices
mai1 <- tweets.df%>%filter(screenName == "SaffCulverwell") %>%
  select(text) %>% head(1)
mai2 <- tweets.df%>%filter(screenName == "lanadelskinny") %>%
  select(text) %>% head(1)
# textos de usuários detectados com menores índices
mei1 <- tweets.df%>%filter(screenName == "DepressionRoots") %>%
  select(text) %>% head(1)
mei2 <- tweets.df%>%filter(screenName == "juliaweitz2") %>%
  select(text) %>% head(1)
print(c(mai1,mai2,mei1,mei2))

```
</div>


# Referências bibliográficas


