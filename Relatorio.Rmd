---
title: "Seminário - Mineração de Texto"
author: "Fabiana, Fernando, Mário, Rafael e Rodney"
date: "Junho de 2017"
output: 
  html_document: 
    highlight: haddock
    number_sections: yes
    theme: journal
    toc: yes
    toc_depth: 2
    toc_float:
      collapsed: no
      smooth_scroll: no
bibliography: bibliografia.bib
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r,echo=FALSE,message=FALSE}
## Adicionar todos os pacotes que serão utilizados AQUI
```

# Metodologia

## Descrição dos dados
A base de dados utilizada contém 30000 tweets extraídos com auxílio da função $\texttt{searchTwitter}$ do pacote $\texttt{twitteR}$. O banco de dados é composto por 10000 tweets escritos em inglês durante o período que compreende 01/01/2015 a 06/06/2017, contendo as palavras "depression", "depressive" e "depressed". A função $\texttt{searchTwitter}$ retorna uma lista com diversas informações, então faz-se necessário aplicar a função $\texttt{twListToPdf}$, também disponível no pacote $\texttt{twitteR}$, para transformar a lista do twitter em um dataframe compatível com os métodos  $\texttt{tidy}$ e $\texttt{tm}$.

# Análise de tópicos

Um interesse usual em análises de grandes volumes de textos é classicar os documentos em diferentes tópicos, permitindo idetenficar ou validar grupos entre os documentos analisados.  Uma forma de realizar esse tipo de análise é utilizar o método de alocação latente de Dirichlet (LDA, na sigla em inglês), que foi proposto por @blei2003latent. Esse método é bastante conhecido na literatura de mineração de texto pela sua eficiência, já tendo sido aplicado em análises de e-mails, livros digitais e notícias, por exemplo, como destacam @berry2010text.

As principais características do LDA, como apresentam @Silge2017Text, são as seguintes:

* Documentos diferentes são formados por misturas de tópicos: Dados dois documentos $A$ e $B$, e tópicos distintos 1 e 2, podemos ter que o $A$ é formado em 75% por conteúdo sobre o tópico 1 e em 25% sobre o tópico 2, enquanto $B$ é formado em 40% sobre o tópico 1 e 60% sobre o tópico 2, por exemplo.

* Diferentes palavras podem fazer parte de diferentes tópicos: a palavra "estudante" pode estar mais associada a um tópico sobre universidades enquanto que "cliente" pode ser mais associado a um tópico sobre empresas, mas o termo "dados" pode estar relacionado de maneira similar a ambos esses tópicos.

Para exemplificar a suposição do modelo LDA vamos considerar as seguintes notações: uma palavra $w$ é uma unidade discreta de um conjunto que forma o vocabulário utilizado; um documento $\mathbf{w} = \left(w_1,\ldots,w_N\right)$ é um conjunto de $N$ palavras; um corpo $D=\left\{\mathbf{w}_1,\ldots,\mathbf{w}_M\right\}$ é um conjunto de $M$ documentos. Adicionalmente, no LDA o número de tópicos existentes é assumido conhecido, mas os tópicos em si são variáveis latentes que não conhecemos e desejamos estimar. Dessa maneira, @blei2003latent consideram as seguintes suposições na geração do corpo:

1. Gera-se $N\sim \textrm{Pois}\left(\lambda\right)$;
2. Gera-se $\theta = \textrm{Dirichlet}\left(\mathbf{\alpha}\right)$, o qual será o vetor de probabilidades dos $k$ tópicos;
3. Para cada uma das $N$ palavras $w_n$:

+ Sorteia-se um tópico $z_n \sim \textrm{Multinomial}\left(k,\theta\right)$

+ Sorteia-se uma palavra $w_n$ de $p\left(w_n|z_n,\beta\right)$, que segue uma distribuição multinomial cujas probabilidades são condicionadas no tópico $z_n$ e em um vetor desconhecido de parâmetros $\beta$.


A aplicação do LDA apresentada por @blei2003latent é baseada em um modelo Bayesiano com três níveis hierárquicos, e permite estimar a probabilidade que cada palavra tem de pertencer à cada um dos tópicos, bem como estimar a probabilidade de cada documento ser sobre cada tópico.

No programa $\texttt{R}$ a análise de tópicos pode ser realizada através do pacote $\texttt{topicmodels}$, utilizando a função $\texttt{LDA}$. Uma aplicação dessa função do $\texttt{R}$ é fornecida por @Silge2017Text em um exemplo onde livros distintos são tratados como tópicos e seus respectivos capítulos como documentos; no exemplo dos autores, mostra-se que o LDA consegue classificar quase todos capítulos corretamente em seus respectivos livros, demonstrando a eficiência do método.

# Análise de sentimentos

Em análise de sentimentos o principal objetivo consiste em fazer "inferência"" sobre sentimetos expressos em forma de texto. @messias2017 cita algumas das recentes aplicações da referida metodologia, sendo as principais:

* Monitorar a reputação de alguma empresa ou marca;
* Fornecer perspectivas analíticas para investidores sobre determinado mercado (se certo mercado tem potencial ou não);
* Rastrear opiniões associadas a certos políticos (tais informações são úteis para o marketing do candidato) e
* Proporcionar meios de mensurar o bem-estar dos usuários de certo modelo de smartphone.

@goncalves2013 discute que não há a "melhor" técnica para se aplicar em análise de sentimentos. Conclusão semelhante foi obtida por @ribeiro2016 após comparar 22 métodos diferentes em 18 documentos onde não foi possível encontrar um método que fosse igualmente bom, em termos de classificação, para todos os textos. 

Na aplicação sobre depressão iremos considerar os dicionários de sentimentos **afinn**(@afinn2011), **bing**(@bing2005) e **nrc**(@nrc2013), por estarem disponíveis no R.

# Referências bibliográficas

