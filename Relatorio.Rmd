---
title: "Seminário - Mineração de Texto"
author: "Fabiana, Fernando, Mário, Rafael e Rodney"
date: "Junho de 2017"
output: 
  html_document: 
    highlight: haddock
    number_sections: yes
    theme: journal
    toc: yes
    toc_depth: 2
    toc_float:
      collapsed: no
      smooth_scroll: no
bibliography: bibliografia.bib
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Metodologia

## Descrição dos dados
A base de dados utilizada contém 30000 tweets extraídos com auxílio da função $\texttt{searchTwitter}$ do pacote $\texttt{twitteR}$. O banco de dados é composto por 10000 tweets escritos em inglês durante o período que compreende 01/01/2015 a 06/06/2017, contendo as palavras "depression", "depressive" e "depressed". A função $\texttt{searchTwitter}$ retorna uma lista com diversas informações, então faz-se necessário aplicar a função $\texttt{twListToPdf}$, também disponível no pacote $\texttt{twitteR}$, para transformar a lista do twitter em um dataframe compatível com os métodos  $\texttt{tidy}$ e $\texttt{tm}$.

## Análise de tópicos

Um interesse usual em análises de grandes volumes de textos é classicar os documentos em diferentes tópicos, permitindo idetenficar ou validar grupos entre os documentos analisados.  Uma forma de realizar esse tipo de análise é utilizar o método de alocação latente de Dirichlet (LDA, na sigla em inglês), que foi proposto por @blei2003latent. Esse método é bastante conhecido na literatura de mineração de texto pela sua eficiência, já tendo sido aplicado em análises de e-mails, livros digitais e notícias, por exemplo, como destacam @berry2010text.

As principais características do LDA, como apresentam @Silge2017Text, são as seguintes:

* Documentos diferentes são formados por misturas de tópicos: Dados dois documentos $A$ e $B$, e tópicos distintos 1 e 2, podemos ter que o $A$ é formado em 75% por conteúdo sobre o tópico 1 e em 25% sobre o tópico 2, enquanto $B$ é formado em 40% sobre o tópico 1 e 60% sobre o tópico 2, por exemplo.

* Diferentes palavras podem fazer parte de diferentes tópicos: a palavra "estudante" pode estar mais associada a um tópico sobre universidades enquanto que "cliente" pode ser mais associado a um tópico sobre empresas, mas o termo "dados" pode estar relacionado de maneira similar a ambos esses tópicos.

Para exemplificar a suposição do modelo LDA vamos considerar as seguintes notações: uma palavra $w$ é uma unidade discreta de um conjunto que forma o vocabulário utilizado; um documento $\mathbf{w} = \left(w_1,\ldots,w_N\right)$ é um conjunto de $N$ palavras; um corpo $D=\left\{\mathbf{w}_1,\ldots,\mathbf{w}_M\right\}$ é um conjunto de $M$ documentos. Adicionalmente, no LDA o número de tópicos existentes é assumido conhecido, mas os tópicos em si são variáveis latentes que não conhecemos e desejamos estimar. Dessa maneira, @blei2003latent consideram as seguintes suposições na geração do corpo:

1. Gera-se $N\sim \textrm{Pois}\left(\lambda\right)$;
2. Gera-se $\theta = \textrm{Dirichlet}\left(\mathbf{\alpha}\right)$, o qual será o vetor de probabilidades dos $k$ tópicos;
3. Para cada uma das $N$ palavras $w_n$:

+ Sorteia-se um tópico $z_n \sim \textrm{Multinomial}\left(k,\theta\right)$

+ Sorteia-se uma palavra $w_n$ de $p\left(w_n|z_n,\beta\right)$, que segue uma distribuição multinomial cujas probabilidades são condicionadas no tópico $z_n$ e em um vetor desconhecido de parâmetros $\beta$.


A aplicação do LDA apresentada por @blei2003latent é baseada em um modelo Bayesiano com três níveis hierárquicos, e permite estimar a probabilidade que cada palavra tem de pertencer à cada um dos tópicos, bem como estimar a probabilidade de cada documento ser sobre cada tópico.

No programa $\texttt{R}$ a análise de tópicos pode ser realizada através do pacote $\texttt{topicmodels}$, utilizando a função $\texttt{LDA}$. Uma aplicação dessa função do $\texttt{R}$ é fornecida por @Silge2017Text em um exemplo onde livros distintos são tratados como tópicos e seus respectivos capítulos como documentos; no exemplo dos autores, mostra-se que o LDA consegue classificar quase todos capítulos corretamente em seus respectivos livros, demonstrando a eficiência do método.

## Análise de sentimentos

Em análise de sentimentos o principal objetivo consiste em fazer "inferência"" sobre sentimetos expressos em forma de texto. @messias2017 cita algumas das recentes aplicações da referida metodologia, sendo as principais:

* Monitorar a reputação de alguma empresa ou marca;
* Fornecer perspectivas analíticas para investidores sobre determinado mercado (se certo mercado tem potencial ou não);
* Rastrear opiniões associadas a certos políticos (tais informações são úteis para o marketing do candidato) e
* Proporcionar meios de mensurar o bem-estar dos usuários de certo modelo de smartphone.

@goncalves2013 discute que não há a "melhor" técnica para se aplicar em análise de sentimentos. Conclusão semelhante foi obtida por @ribeiro2016 após comparar 22 métodos diferentes em 18 documentos onde não foi possível encontrar um método que fosse igualmente bom, em termos de classificação, para todos os textos. 

Na aplicação sobre depressão iremos considerar os dicionários de sentimentos **afinn**(@afinn2011), **bing**(@bing2005) e **nrc**(@nrc2013), por estarem disponíveis no R. Os três dicionários são compostos por unigramas, i.e., palavras únicas. Os vocabulários contém palavras em que são associados scores relativos a sentimentos positivos ou negativos. No caso do **nrc** há associação de palavras a sentimentos como alegria, raiva, tristeza, negatividade, surpresa, medo e desgosto. Esta classificação é feita de modo binário (sim ou não), se determinada palavra corresponde a determinado sentimento. Já no vocabulário **bing** as palavras são classificadas, também de modo binário, porém não há distinção de sentimentos. As palavras ou são associadas a sentimentos positivos ou a negativos. Por fim, o vocabulário **afinn** atribui scores que vão de -5 a 5 para as palavras. De modo que quanto mais próximo de -5 mais negativa é aquela palavra e, de modo análogo, quanto mais próximo de 5 mais posiva é a palavra. Os três vocabulários estão disponívels no $\texttt{R}$ no pacote $\texttt{tidytext}$. 

Geralmente os dicionários são elaborados pelos próprios autores com auxílio de crowdsourcing. É haver algum tipo de validação cruzada para testar o dicionário criado. Neste contexto fica evidente que os vocabulário são contemporâneos, ou seja, não é recomendado aplicar um dicionário de sentimentos atual para analisar um texto de séculos atrás. A análise pode ser feita, mas devem ser tomados os devidos cuidados ao analisar os achados.

Iniciamos a análise de sentimentos com o vocabulário **nrc** para obtermos palavras relacionadas a cada um dos sentimos, sendo eles alegria, raiva, tristeza, negatividade, surpresa, medo e desgosto, de modo que obtemos gráficos de contagem de palavras para cada um deles. Essa técnica permite avaliar quais palavras estão associadas a tais sentimentos no contexto de depressão. Prosseguimos a análise de sentimentos com o dicionário **bing**, sendo possível construir índices baseados nos tipos de palavras (positiva ou negativa) e na quantidade de ocorrência das mesmas em um grupo de $n$ linhas. Esse tipo de técnica permite avaliar alterações, caso existam, de sentimentos ao longo do texto. Note que a quantidade de linhas que serãoagrupadas depende do tipo e do tamanho do texto que está sendo análisado. Ainda utilizando o dicionário **bing**, apresentamos uma núvem de palavras de sentimentos, isto é, uma núvem de palavras com distinção entre palavras positivas e negativas. Prosseguimos a análise de sentimentos comparando os três dicionários, de modo a observar se há alguma discrepância em algum deles. 

# Resultados e discussões

## Análise de sentimentos

```{r, message=FALSE,results='hide',echo=TRUE}

if("dplyr" %in% rownames(installed.packages())==FALSE)
{install.packages("dplyr")};library(dplyr)

if("stringr" %in% rownames(installed.packages())==FALSE)
{install.packages("stringr")};library(stringr)

if("tidytext" %in% rownames(installed.packages())==FALSE)
{install.packages("tidytext")};library(tidytext)

if("tidyr" %in% rownames(installed.packages())==FALSE)
{install.packages("tidyr")};library(tidyr)

if("ggplot2" %in% rownames(installed.packages())==FALSE)
{install.packages("ggplot2")};library(ggplot2)

if("twitteR" %in% rownames(installed.packages())==FALSE)
{install.packages("twitteR")};library(twitteR)

if("tibble" %in% rownames(installed.packages())==FALSE)
{install.packages("tibble")};library(tibble)

udemytweets <-readRDS("depression_tweets_final.gzip")

tweets.df <- twListToDF(udemytweets) ##CALMA QUE VAI DEMORAR

tweets_tidy_df <- as_tibble(tweets.df)
# Limpando a base de dados

replace_reg <- "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https"
unnest_reg  <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"

data("stop_words")

mystopwords <- c(stop_words$word)

tidy_tweets <- tweets_tidy_df %>% 
  filter(!str_detect(text, "^RT"),
         text != "im",
         text != "ur",
         text != "af",
         text != "wcw",
         text != "shes",
         text != "booktweeter0",
         text != "bktwr",
         !str_detect(text, "[0-9]"),
         !str_detect(text, ":"),
         !str_detect(text, "textless")) %>%
  mutate(text = str_replace_all(text, replace_reg, "")) %>%
  unnest_tokens(word, text, token = "regex") %>%
  filter(!word %in% mystopwords,
         str_detect(word, "[a-z]")) %>%
  anti_join(stop_words)

nrneg <- get_sentiments("nrc") %>% 
  filter(sentiment == "negative")

tidy_tweets %>%
  inner_join(nrneg) %>%
  count(word, sort = TRUE)%>%
  filter(n > 25 & n < 500) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab("Sentiment = \"Negative\"") +
  ylab("Número de ocorrências")+
  coord_flip()
```
```{r message=FALSE,results='hide',echo=TRUE}
#####sadness    
nrsad <- get_sentiments("nrc") %>% 
  filter(sentiment == "sadness")

tidy_tweets %>%
  inner_join(nrsad) %>%
  count(word, sort = TRUE) %>%
  filter(n > 25 & n < 500) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab("Sentiment = \"Sadness\"") +
  ylab("Número de ocorrências")+
  coord_flip()
```
```{r message=FALSE,results='hide',echo=TRUE}
#####         anger                      ####   
nrang <- get_sentiments("nrc") %>% 
  filter(sentiment == "anger")

tidy_tweets %>%
  inner_join(nrang) %>%
  count(word, sort = TRUE) %>%
  filter(n > 15 & n < 500) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab("Sentiment = \"Anger\"") +
  ylab("Número de ocorrências")+
  coord_flip() 
```
```{r message=FALSE,results='hide',echo=TRUE}
#####  fear      
nrfear <- get_sentiments("nrc") %>% 
  filter(sentiment == "fear")

tidy_tweets %>%
  inner_join(nrfear) %>%
  count(word, sort = TRUE) %>%
  filter(n > 25 & n < 500) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab("Sentiment = \"Fear\"") +
  ylab("Número de ocorrências")+
  coord_flip() 
```
```{r message=FALSE,results='hide',echo=TRUE}
##### disgust 
nrdisg <- get_sentiments("nrc") %>% 
  filter(sentiment == "disgust")

tidy_tweets %>%
  inner_join(nrdisg) %>%
  count(word, sort = TRUE) %>%
  filter(n > 15 & n < 500) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab("Sentiment = \"Disgust\"") +
  ylab("Número de ocorrências")+
  coord_flip() 
```

Utilizando o dicionário **nrc**, observamos a frequência de palavras relacionadas aos sentimentos contidos no dicionário. O objetivo deste tipo de análise é verificar quais palavras estão associadas a quais sentimentos no âmbito da análise em questão.

É interessante destacar que palavras relacionadas a ansiedade, suicídio, morte e cansaço são recorrentes com alta frequência quando contrastamos os sentimentos "negative", "anger", "fear" e "disgust". Este resultado é interessante pois a literatura comumente não encontra alta frequência de palavras associadas a sentimentos distintos. A palavra "anxiety" merece atenção especial uma vez que há referências robustas relacionando ansiedade com depressão e, possivelmente, suicídio. 

```{r message=FALSE,results='hide',echo=TRUE}
#####surprise  
nrsurp <- get_sentiments("nrc") %>% 
  filter(sentiment == "surprise")

tidy_tweets %>%
  inner_join(nrsurp) %>%
  count(word, sort = TRUE) %>%
  filter(n > 15 & n < 500) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab("Sentiment = \"Surprise\"") +
  ylab("Número de ocorrências")+
  coord_flip() 
```

Ao comparar a frequência de palavras relacionadas ao sentimento "surprise" observa-se a presença de diversas palavras positivas. Um resultado curioso é a presença da palavra "Trump", uma óbvia referência ao presidente dos Estados Unidos Donald Trump. Ainda avaliado as ocorrências em "surprise" nota-se que "hope" é uma palavra que aparece com relativa frequência nos tweets relacionados com depressão. Obviamente, "money", também aparece com certa frequência

```{r message=FALSE,results='hide',echo=TRUE}
################# Dicionário Bing      
 tweets_tidy_df %>% 
  filter(!str_detect(text, "^RT"),
         text != "im",
         text != "ur",
         text != "af",
         text != "wcw",
         text != "shes",
         text != "booktweeter0",
         text != "bktwr",
         !str_detect(text, "[0-9]"),
         !str_detect(text, ":"),
         !str_detect(text, "textless")) %>%
  mutate(text = str_replace_all(text, replace_reg, ""),
         line = row_number()) %>%
  unnest_tokens(word, text, token = "regex") %>%
  anti_join(stop_words) %>%
  filter(!word %in% mystopwords,
         str_detect(word, "[a-z]"))%>%
  inner_join(get_sentiments("bing"))%>%
  count(index = line %/% 150, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative) %>%
  ggplot(aes(index, sentiment)) +
  geom_col(show.legend = FALSE) +
  xlab("Index")+
  ylab("Sentimento")
```

O gráfico acima, criado a partir do dicionário **bing** é conciso em informar que a base de dados em questão possui elevada aparição de palavras negativas. Note que no dicionário **nrc** encontramos certas palavras positivas associadas ao sentimento "surprise", contudo essas palavras não alteram a característica extremamente negativa do texto. Esta conclusão é obtida ao observarmos que em grupos de 150 não há nenhum com score positivo. 
```{r message=FALSE,results='hide',echo=TRUE}
#################################################################
################# Dicionário afinn              #################     

afinn <-  tweets_tidy_df %>% 
          filter(!str_detect(text, "^RT")) %>%
          mutate(text = str_replace_all(text, replace_reg, ""),
          line = row_number()) %>%
          unnest_tokens(word, text, token = "regex") %>%
          anti_join(stop_words) %>%
          filter(!word %in% mystopwords,
          str_detect(word, "[a-z]"))%>%
          inner_join(get_sentiments("afinn")) %>% 
          group_by(index = line %/% 20) %>% 
          summarise(sentiment = sum(score)) %>% 
          mutate(method = "AFINN")
#################################################################
################# Comparação de Dicionário     #################     
bing_and_nrc <- bind_rows(tweets_tidy_df %>%
                            filter(!str_detect(text, "^RT")) %>%
                            mutate(text = str_replace_all(text, replace_reg, ""),
                            line = row_number()) %>%
                            unnest_tokens(word, text, token = "regex") %>%
                            anti_join(stop_words) %>%
                            filter(!word %in% mystopwords,
                                     str_detect(word, "[a-z]"))%>% 
                            inner_join(get_sentiments("bing")) %>%
                            mutate(method = "Bing et al."),
                            tweets_tidy_df %>%
                            filter(!str_detect(text, "^RT")) %>%
                            mutate(text = str_replace_all(text, replace_reg, ""),
                                     line = row_number()) %>%
                            unnest_tokens(word, text, token = "regex") %>%
                            anti_join(stop_words) %>%
                            filter(!word %in% mystopwords,
                                     str_detect(word, "[a-z]"))%>% 
                            inner_join(get_sentiments("nrc") %>% 
                            filter(sentiment %in% c("positive","negative"))) %>%
                            mutate(method = "NRC")) %>%
                            count(method, index = line %/% 20, sentiment) %>%
                            spread(sentiment, n, fill = 0) %>%
                            mutate(sentiment = positive - negative)

bind_rows(afinn,bing_and_nrc) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  ylab("Score")+
  xlab("Index")+
  facet_wrap(~method, ncol = 1, scales = "free_y") 
```

A comparação entre os três dicionários corrobora o elevado caráter negativo das palavras utilizadas. É relevante ressaltar que, embora o dicionário **afinn** apresente os menores scores, é o dicionário que aponta mais scores positivos para grupos de 20 palavras. No caso aqui considerado os dicionários evidenciam resultados parecidos entre si. Para fins de comparação utilizou-se, para o vocabulário **nrc**, as palavras relacionadas aos sentimentos "positive" e "negative" do referido dicionário.

As análises realizadas até este ponto foram realizadas por meio de unigramas, isto é, análises de palavra por palavra em separado. Análises baseadas em unigramas podem não ser a melhor opção pois há composições de palavras que alteram completamente o sentido da frase. Um exemplo intuitivo e iminente são as palavras precedidas por "not". Quando este é o caso as análises de unigramas captam apenas o sentido de uma palavra, não há como saber se a referida palavra está precedida por "not", o que obviamente altera complemente o sentido da expressão. Para evitar tais problemas e obtermos as sequências de palavras mais frequentes no texto prosseguimos com uma análise baseada em bigramas, isto é, análises baseadas em composições de duas palavras ao invés de uma.

```{r message=FALSE,results='hide',echo=TRUE}
#### Bigramas

tidy_tweets_big <- tweets_tidy_df %>% 
  filter(!str_detect(text, "^RT"),
         text != "im",
         text != "ur",
         text != "af",
         text != "wcw",
         text != "shes",
         text != "booktweeter0",
         text != "bktwr",
         !str_detect(text, "[0-9]"),
         !str_detect(text, ":"),
         !str_detect(text, "textless")) %>%
  mutate(text = str_replace_all(text, replace_reg, "")) %>%
  unnest_tokens(word, text, token = "ngrams",n=2) %>%
  filter(!word %in% mystopwords,
         str_detect(word, "[a-z]"))

tidy_tweets_big %>%
  count(word, sort = TRUE)

bigrams_separated <- tidy_tweets_big %>%
  separate(word, c("word1", "word2"), sep = " ")

bigrams_separated %>%
  filter(word1 == "depression") %>%
  count(word1, word2, sort = TRUE)

AFINN <- get_sentiments("afinn")

# We can then examine the most frequent words that were preceded by “not” and 
# were associated with a sentiment.
depression_words <- bigrams_separated %>%
  filter(word1 == "depression") %>%
  inner_join(AFINN, by = c(word2 = "word")) %>%
  count(word2, score, sort = TRUE) %>%
  ungroup()

depression_words

depression_words %>%
  mutate(contribution = n * score) %>%
  arrange(desc(abs(contribution))) %>%
  head(20) %>%
  mutate(word2 = reorder(word2, contribution)) %>%
  ggplot(aes(word2, n * score, fill = n * score > 0)) +
  geom_col(show.legend = FALSE) +
  xlab("Palavras precedidas por \"depression\"") +
  ylab("Score * número de ocorrências") +
  coord_flip()
```

Em análise de bigramas algo relevante é a quantidade de vezes que alguma palavra de interesse, no caso "depression", é precedida de outras palavras. Observa-se a ocorrência de algumas palavras relacionadas positivas, sendo as principais "love" e "win". Pelo espectro negativo há de se ressaltar o elevado número de vezes em que a palavra "depression" é precedida de "anxiety", "kills" e palavras relacionadas a suicídio. Confirma-se, a priori, os achados nas análises de unigramas quando se comparou a ocorrência de palavras relacionadas a sentimentos do dicionário **nrc**. Naquele caso as palavras relacionadas a ansiedade e suicídio também apareceram com frequência elevada.

Ainda no contexto de bigramas há de se mencionar as redes de palavras. As redes de palavras são dispositivos visuais que auxiliam na compreensão da base de dados e dos sentimentos envolvidos.

```{r message=FALSE,results='hide',echo=TRUE}

if("igraph" %in% rownames(installed.packages())==FALSE)
{install.packages("igraph")};library(igraph)
if("ggraph" %in% rownames(installed.packages())==FALSE)
{install.packages("ggraph")};library(ggraph)
### Rede de palavras

bigrams_filtered <- bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

bigram_counts <- bigrams_filtered %>% 
  count(word1, word2, sort = TRUE)

bigram_graph <- bigram_counts %>%
  filter(n > 10) %>%
  graph_from_data_frame()

bigram_graph

set.seed(2016)

a <- grid::arrow(type = "closed", length = unit(.15, "inches"))

## REDE DE PALAVRAS
ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n,edge_width = n), edge_colour = "darkred", show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "royalblue", size = 5) +
  geom_node_text(aes(label = name), repel=TRUE, point.padding = unit(0.2, "lines")) +
  theme_void()
```

```{r message=FALSE,results='hide',echo=TRUE}

if("devtools" %in% rownames(installed.packages())==FALSE)
{install.packages("devtools")};library(devtools)
if("widyr" %in% rownames(installed.packages())==FALSE)
{install_github("dgrtwo/widyr")};library(widyr)

#Counting and correlating pairs of words with the widyr package
mystopwords_w_dep <- c(stop_words$word,"depression,")

word_cors <- tidy_tweets %>%
  group_by(word) %>%
  filter(!word %in% mystopwords_w_dep,
         str_detect(word, "[a-z]"),
         n() >= 15) %>%
  pairwise_cor(word, screenName, sort = TRUE)

#Palavras correlacionadas com depression
word_cors %>%
  filter(item1 %in% c("anxiety")) %>%
  group_by(item1) %>%
  top_n(8) %>%
  ungroup() %>%
  mutate(item2 = reorder(item2, correlation)) %>%
  ggplot(aes(item2, correlation)) +
  geom_bar(stat = "identity") +
  facet_wrap(~ item1, scales = "free") +
  ylab("Correlação")+
  xlab("Palavras")+
  coord_flip()
```

## Análise de tópicos

Nesta etapa será realizada uma análise de tópicos para verificar se o método LDA é capaz de encontrar algum agrupar os tweets de alguma forma. Na análise, cada usuário do Twitter será visto como o "documento" do qual o texto faz parte. Para isso, criamos um banco de dados onde as palavras e suas frequências são agrupadas por usuários, identificados pelo $\texttt{screenName}$. Adicionalmente, será feita a suposição de que os textos fazem parte de dois grupos desconhecidos e através da função $\texttt{LDA}$ do pacote $\texttt{topicmodels}$, serão obtidas as probabilidades de cada palavra e de cada usuário (documento) pertencer a cada um dos grupos, que serão identificados pelos números 1 e 2.

```{r message=FALSE,results='hide',echo=TRUE}
if("topicmodels" %in% rownames(installed.packages())==FALSE)
{install.packages("topicmodels")};library(topicmodels)

# Criando um tidy com contando as palavras por usuário
tidy_data <- tidy_tweets %>%
    group_by(screenName) %>%
    count(word, sort = TRUE) %>%
    filter(n >= 0)
# criando um DocumentTermMatrix para ser usado na função LDA
depre_dtm <- tidy_data %>% cast_dtm(screenName, word, n)

# aplicando a análise de tópicos
depre_lda <- LDA(depre_dtm, k = 2, control = list(seed = 1234))

# usando o tidy para extrair as probabilidades tópico/palavra
depre_topics <- tidy(depre_lda, matrix = "beta")
```

```{r message=FALSE,results='hide',echo=TRUE}
# aqui extraímos as palavras com maiores probabilidades de pertecerem
# a cada um dos tópicos
depre_top_terms <- depre_topics %>%
  group_by(topic) %>%
  top_n(5, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)
# gerando o gráfico
depre_top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  ylab(expression(beta))+
  xlab("Termo")+
  coord_flip()
```

Após o método LDA ser aplicado, o índice $\texttt{beta}$ fornece a probabilidade de cada palavra pertencer a um dos grupos. Durante a análise, notamos que não parece haver grupos distintos bem definidos nos tweets analisados, sendo os grupos 1 e 2 bastante similiras e com várias palavras em comum. Tal resultados também foi verificado quando se connsidera números maiores ($k$) de grupos desconhecidos. No gráfico acima são apresentadas para cada grupo identificado pelo LDA as palavras que possuem as maiores de $\texttt{beta}$. Apesar dos grupos 1 e 2 serem bastante parecidos, podemos observar que o primeiro grupo parece estar mais relacionado com o estado "depressed", enquanto no segundo grupo tem-se uma ênfase maior no sentimento "depression".

```{r message=FALSE,echo=TRUE}
# Aqui calculamos a probabilidade de cada pessoa escrever sobre
# cada um dos tópicos
depre_topics_id <- tidy(depre_lda, matrix = "gamma")
depre_topics_id %>% group_by(topic) %>%
  top_n(3) %>% arrange(topic, desc(gamma))

# Aqui analisamos algumas das pessoas com as maiores probabilidades de 
# escrever sobre algum dos tópicos

# Exemplo 1
exemplo1 <- tweets.df %>% filter(screenName == "_Depressed_Zuka") %>%
  select(text)
exemplo1$text[15]

# Exemplo 2
exemplo2 <- tweets.df %>% filter(screenName == "Quixotitron_4") %>%
  select(text)
exemplo2$text[1]

# Exemplo 3
exemplo3 <- tweets.df %>% filter(screenName == "RF_NYC_2010") %>%
  select(text)
exemplo3$text[5]

# Exemplo 4
exemplo4 <- tweets.df %>% filter(screenName == "DepressionRoots") %>%
  select(text)
exemplo4$text[2]
```

Como mencionado, pelo LDA também podemos estimar uma probabilidade que cada usuário tem de pertencer a cada um dos grupos. De maneira similar como foi feito para as palavras, no código anterior identificamos dentro dos grupos 1 e 2 quais pessoas tinham as maiores probabilidades, que é dada pelo índice $\texttt{gamma}$. Acima são mostrados alguns textos dos usuários identificados pelo LDA, onde podemos ver que alguns dos textos parecem ser provenientes de pessoas com um nível expressivo de descontentamento ou tristeza, como os exemplos 1 e 3. No exemplo 2 temos um exemplo onde o usuário escreve diversos trechos relacionados ao livro Dom Quixote de Miguel de Cervantes, onde seus textos podem ter algum grau de tristeza mas não necessariamente indicar que a pessoa tenha depressão. No exemplo 4, o usuário escreve sobre depressão, o que pode explicar o fato dele ser incluído no grupo sobre o sentimento "depression". Em geral, notamos que o método LDA apresenta dificuldade em encontrar grupos dentro dos tweets analisados, mas que a medida de probabilidade para cada pessoa ainda pode fornecer um indicativo se cada pessoa está apresentando textos que se destacam dos demais, o que poderia ser um possível indício de sentimentos negativos que estajam relacionados ao estado de depressão.

# Referências bibliográficas

